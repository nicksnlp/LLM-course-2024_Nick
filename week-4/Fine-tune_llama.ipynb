{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install huggingface_hub transformers datasets peft accelerate wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import wandb\n",
    "from google.colab import drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Use your Hugging Face and Weights & Biases API keys for authentication\n",
    "HUGGINGFACE_API_KEY = 'your_huggingface_api_key'  # Replace with your Hugging Face API Key\n",
    "WANDB_API_KEY = 'your_wandb_api_key'  # Replace with your Weights & Biases API Key\n",
    "\n",
    "# Login to Hugging Face\n",
    "login(token=HUGGINGFACE_API_KEY)\n",
    "\n",
    "# Login to Weights & Biases\n",
    "wandb.login(key=WANDB_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive to save models\n",
    "drive.mount('/content/drive/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Create and Prepare Dataset for Hallucination Detection\n",
    "This dataset will have two fields:\n",
    "\n",
    "text: The sentence.\n",
    "labels: The label for each token in the sentence (0 for correct, 1 for hallucinated).\n",
    "For simplicity, we'll manually label some sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Example dataset with manual labeling of hallucinations\n",
    "data = [\n",
    "    {\"text\": \"The Eiffel Tower is located in Berlin, Germany.\", \"labels\": [0, 1, 1, 0, 0]},  # \"Berlin, Germany\" is hallucinated\n",
    "    {\"text\": \"The capital of France is Paris.\", \"labels\": [0, 0, 0, 0, 0]},  # Correct sentence, no hallucinations\n",
    "    {\"text\": \"The Amazon River flows through Asia.\", \"labels\": [0, 0, 0, 1]},  # \"Asia\" is hallucinated\n",
    "]\n",
    "\n",
    "# Convert the dictionary to a Hugging Face dataset\n",
    "dataset = Dataset.from_dict(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n",
    "\n",
    "# Define the tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "# Apply the tokenization function\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load model for token classification\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"meta-llama/Llama-2-7b-hf\", num_labels=2)\n",
    "\n",
    "# Define label names (0 = correct, 1 = hallucinated)\n",
    "model.config.id2label = {0: \"correct\", 1: \"hallucinated\"}\n",
    "model.config.label2id = {\"correct\": 0, \"hallucinated\": 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/NLP/MODELS/FineTunedModel\",  # Path to save the model\n",
    "    evaluation_strategy=\"epoch\",  # Evaluate the model every epoch\n",
    "    learning_rate=2e-5,  # Learning rate\n",
    "    per_device_train_batch_size=4,  # Training batch size\n",
    "    per_device_eval_batch_size=8,  # Evaluation batch size\n",
    "    num_train_epochs=3,  # Number of epochs\n",
    "    weight_decay=0.01,  # Weight decay for optimization\n",
    "    logging_dir=\"/content/drive/MyDrive/NLP/MODELS/Logs\",  # Save logs to Google Drive\n",
    "    logging_steps=10,  # Log every 10 steps\n",
    "    push_to_hub=False,  # Set to True to upload the model after training\n",
    "    report_to=\"wandb\",  # Report metrics to Weights & Biases\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the Trainer with model, training arguments, and datasets\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets,  # Use the tokenized dataset for training\n",
    "    eval_dataset=tokenized_datasets,  # Optional: Use the same dataset for evaluation\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Save the fine-tuned model to Google Drive\n",
    "model_save_path = \"/content/drive/MyDrive/NLP/MODELS/FineTunedModel\"\n",
    "trainer.save_model(model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Optionally, push the fine-tuned model to Hugging Face Hub\n",
    "model.push_to_hub(\"your_huggingface_username/your_model_repo_name\")\n",
    "tokenizer.push_to_hub(\"your_huggingface_username/your_model_repo_name\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INFERENCE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Inference function for hallucination detection\n",
    "def infer_with_model(input_text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    \n",
    "    # Predict the token labels (hallucination vs. correct)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits  # Raw logits output from the model\n",
    "\n",
    "    # Get the predicted labels (0 for correct, 1 for hallucinated)\n",
    "    predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    # Decode the tokens from the input text\n",
    "    tokens = tokenizer.tokenize(input_text)\n",
    "    \n",
    "    # Get the corresponding predicted labels for each token\n",
    "    labeled_tokens = list(zip(tokens, predicted_labels[0].tolist()))\n",
    "    \n",
    "    # Create a list of hallucinated words\n",
    "    hallucinated_words = [token for token, label in labeled_tokens if label == 1]\n",
    "\n",
    "    return hallucinated_words\n",
    "\n",
    "# Example usage of the inference function\n",
    "input_text = \"The Eiffel Tower is located in Berlin, Germany.\"\n",
    "hallucinated_words = infer_with_model(input_text)\n",
    "\n",
    "# Print the list of hallucinated words\n",
    "print(\"Hallucinated words:\")\n",
    "print(hallucinated_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REFERENCE:\n",
    "https://chatgpt.com/share/67729fee-da9c-800b-808a-28a722cd3174"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
