{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slSI7Xv36zk_"
      },
      "source": [
        "# In-Context Learning\n",
        "\n",
        "\n",
        "In-context learning is a generalisation of few-shot learning where the LLM is provided a context as part of the prompt and asked to respond by utilising the information in the context.\n",
        "\n",
        "* Example: *\"Summarize this research article into one paragraph highlighting its strengths and weaknesses: [insert article text]”*\n",
        "* Example: *\"Extract all the quotes from this text and organize them in alphabetical order: [insert text]”*\n",
        "\n",
        "A very popular technique that you will learn in week 5 called Retrieval-Augmented Generation (RAG) is a form of in-context learning, where:\n",
        "* a search engine is used to retrieve some relevant information\n",
        "* that information is then provided to the LLM as context\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iezN_Xni6zlA"
      },
      "source": [
        "In this example we download some recent research papers from arXiv papers, extract the text from the PDF files and ask Gemini to summarize the articles as well as provide the main strengths and weaknesses of the papers. Finally we print the summaries to a local html file and as markdown."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ3FWky869ys",
        "outputId": "22ada370-b7a9-45e2-aba6-c0d327b2d789"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRTJDV7m6zlA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import google.generativeai as genai\n",
        "from urllib.request import urlopen, urlretrieve\n",
        "from IPython.display import Markdown, display\n",
        "from pypdf import PdfReader\n",
        "from datetime import date\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "rRxO32xUC9E8"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "iNDMlezJ6zlB"
      },
      "outputs": [],
      "source": [
        "API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDknKw-k6zlB"
      },
      "source": [
        "We select those papers that have been featured in Hugging Face papers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "mIZHexOX6zlB"
      },
      "outputs": [],
      "source": [
        "BASE_URL = \"https://huggingface.co/papers\"\n",
        "page = requests.get(BASE_URL)\n",
        "soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "h3s = soup.find_all(\"h3\")\n",
        "\n",
        "papers = []\n",
        "\n",
        "for h3 in h3s:\n",
        "    a = h3.find(\"a\")\n",
        "    if a:  # Ensure there is an anchor tag\n",
        "        title = a.text.strip()  # Remove any leading/trailing whitespace\n",
        "        link = a.get(\"href\", \"\")  # Safely get the href attribute\n",
        "        if link.startswith(\"/papers\"):  # Verify the link is in the expected format\n",
        "            arxiv_link = link.replace('/papers', '')\n",
        "            papers.append({\"title\": title, \"url\": f\"https://arxiv.org/pdf{arxiv_link}\"})\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for paper in papers:\n",
        "    print(paper[\"title\"])\n",
        "    print(paper[\"url\"])"
      ],
      "metadata": {
        "id": "aXg6nrsmCM-P",
        "outputId": "e0019e7e-523f-4620-ba71-61048b36dbe5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explanatory Instructions: Towards Unified Vision Tasks Understanding and Zero-shot Generalization\n",
            "https://arxiv.org/pdf/2412.18525\n",
            "On the Compositional Generalization of Multimodal LLMs for Medical Imaging\n",
            "https://arxiv.org/pdf/2412.20070\n",
            "Bringing Objects to Life: 4D generation from 3D objects\n",
            "https://arxiv.org/pdf/2412.20422\n",
            "Efficiently Serving LLM Reasoning Programs with Certaindex\n",
            "https://arxiv.org/pdf/2412.20993\n",
            "TangoFlux: Super Fast and Faithful Text to Audio Generation with Flow Matching and Clap-Ranked Preference Optimization\n",
            "https://arxiv.org/pdf/2412.21037\n",
            "Edicho: Consistent Image Editing in the Wild\n",
            "https://arxiv.org/pdf/2412.21079\n",
            "Facilitating large language model Russian adaptation with Learned Embedding Propagation\n",
            "https://arxiv.org/pdf/2412.21140\n",
            "HumanEval Pro and MBPP Pro: Evaluating Large Language Models on Self-invoking Code Generation\n",
            "https://arxiv.org/pdf/2412.21199\n",
            "Training Software Engineering Agents and Verifiers with SWE-Gym\n",
            "https://arxiv.org/pdf/2412.21139\n",
            "OneKE: A Dockerized Schema-Guided LLM Agent-based Knowledge Extraction System\n",
            "https://arxiv.org/pdf/2412.20005\n",
            "PERSE: Personalized 3D Generative Avatars from A Single Portrait\n",
            "https://arxiv.org/pdf/2412.21206\n",
            "Slow Perception: Let's Perceive Geometric Figures Step-by-step\n",
            "https://arxiv.org/pdf/2412.20631\n",
            "Do NOT Think That Much for 2+3=? On the Overthinking of o1-Like LLMs\n",
            "https://arxiv.org/pdf/2412.21187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYXbiCaO6zlB"
      },
      "source": [
        "Code to extract text from PDFs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "jz3vAi3y6zlB"
      },
      "outputs": [],
      "source": [
        "def extract_paper(url):\n",
        "    html = urlopen(url).read()\n",
        "    soup = BeautifulSoup(html, features=\"html.parser\")\n",
        "\n",
        "    # kill all script and style elements\n",
        "    for script in soup([\"script\", \"style\"]):\n",
        "        script.extract()    # rip it out\n",
        "\n",
        "    # get text\n",
        "    text = soup.get_text()\n",
        "\n",
        "    # break into lines and remove leading and trailing space on each\n",
        "    lines = (line.strip() for line in text.splitlines())\n",
        "    # break multi-headlines into a line each\n",
        "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
        "    # drop blank lines\n",
        "    text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "def extract_pdf(url):\n",
        "    pdf = urlretrieve(url, \"pdf_file.pdf\")\n",
        "    reader = PdfReader(\"pdf_file.pdf\")\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text() + \"\\n\"\n",
        "    return text\n",
        "\n",
        "\n",
        "def printmd(string):\n",
        "    display(Markdown(string))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "LNnTai0k6zlB"
      },
      "outputs": [],
      "source": [
        "LLM = \"gemini-1.5-flash\"\n",
        "model = genai.GenerativeModel(LLM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goRd-cgY6zlB"
      },
      "source": [
        "We use Gemini to summarize the papers."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.generate_content(\"tell 3 words\").text"
      ],
      "metadata": {
        "id": "CjIlKUACC1JC",
        "outputId": "bc3ebff8-4551-46cc-9125-c8e697df6fcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "DefaultCredentialsError",
          "evalue": "\n  No API_KEY or ADC found. Please either:\n    - Set the `GOOGLE_API_KEY` environment variable.\n    - Manually pass the key with `genai.configure(api_key=my_api_key)`.\n    - Or set up Application Default Credentials, see https://ai.google.dev/gemini-api/docs/oauth for more information.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-19bf8dadcae6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tell 3 words\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_generative_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrequest_options\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/client.py\u001b[0m in \u001b[0;36mget_default_generative_client\u001b[0;34m()\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_default_generative_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mglm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerativeServiceClient\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_client_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/client.py\u001b[0m in \u001b[0;36mget_default_client\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/client.py\u001b[0m in \u001b[0;36mmake_client\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0;34m\"    - Or set up Application Default Credentials, see https://ai.google.dev/gemini-api/docs/oauth for more information.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             )\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/client.py\u001b[0m in \u001b[0;36mmake_client\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mpatch_colab_gce_credentials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                 \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mga_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDefaultCredentialsError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             e.args = (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, credentials, transport, client_options, client_info)\u001b[0m\n\u001b[1;32m    685\u001b[0m             )\n\u001b[1;32m    686\u001b[0m             \u001b[0;31m# initialize with the provided callable or the passed in class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             self._transport = transport_init(\n\u001b[0m\u001b[1;32m    688\u001b[0m                 \u001b[0mcredentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                 \u001b[0mcredentials_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcredentials_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, host, credentials, credentials_file, scopes, client_cert_source_for_mtls, quota_project_id, client_info, always_use_jwt_access, url_scheme, interceptor, api_audience)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0mhost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{url_scheme}://{host}\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0murl_match_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scheme\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    344\u001b[0m             \u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0mcredentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, host, credentials, credentials_file, scopes, quota_project_id, client_info, always_use_jwt_access, api_audience, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m             )\n\u001b[1;32m     99\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcredentials\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ignore_credentials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             credentials, _ = google.auth.default(\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mscopes_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquota_project_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquota_project_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/auth/_default.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(scopes, request, quota_project_id, default_scopes)\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffective_project_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDefaultCredentialsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CLOUD_SDK_MISSING_CREDENTIALS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mDefaultCredentialsError\u001b[0m: \n  No API_KEY or ADC found. Please either:\n    - Set the `GOOGLE_API_KEY` environment variable.\n    - Manually pass the key with `genai.configure(api_key=my_api_key)`.\n    - Or set up Application Default Credentials, see https://ai.google.dev/gemini-api/docs/oauth for more information."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "499RehE06zlB",
        "outputId": "e2badb31-b0f5-491b-cdf6-99778243f08b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 1/13 [00:02<00:33,  2.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation failed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 2/13 [00:05<00:27,  2.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation failed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 3/13 [00:06<00:19,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation failed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 4/13 [00:10<00:24,  2.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation failed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 5/13 [00:11<00:17,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation failed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 6/13 [00:12<00:12,  1.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation failed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 7/13 [00:13<00:08,  1.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation failed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 8/13 [00:22<00:20,  4.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation failed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 9/13 [00:23<00:12,  3.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation failed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 10/13 [00:24<00:06,  2.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation failed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▍ | 11/13 [00:25<00:04,  2.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation failed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 12/13 [00:26<00:01,  1.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation failed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:27<00:00,  2.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation failed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for paper in tqdm(papers):\n",
        "    try:\n",
        "        paper[\"summary\"] = model.generate_content(\"Summarize this research article into one paragraph without formatting highlighting its strengths and weaknesses. \" + extract_pdf(paper[\"url\"])).text\n",
        "    except:\n",
        "        print(\"Generation failed\")\n",
        "        paper[\"summary\"] = \"Paper not available\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29V9UOe16zlC"
      },
      "source": [
        "We print the results to a html file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIT5mh276zlC"
      },
      "outputs": [],
      "source": [
        "page = f\"<html> <head> <h1>Daily Dose of AI Research</h1> <h4>{date.today()}</h4> <p><i>Summaries generated with: {LLM}</i>\"\n",
        "with open(\"papers.html\", \"w\") as f:\n",
        "    f.write(page)\n",
        "for paper in papers:\n",
        "    page = f'<h2><a href=\"{paper[\"url\"]}\">{paper[\"title\"]}</a></h2> <p>{paper[\"summary\"]}</p>'\n",
        "    with open(\"papers.html\", \"a\") as f:\n",
        "        f.write(page)\n",
        "end = \"</head>  </html>\"\n",
        "with open(\"papers.html\", \"a\") as f:\n",
        "    f.write(end)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iqd4S0to6zlC"
      },
      "source": [
        "We can also print the results to this notebook as markdown."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        },
        "id": "2rDZnqME6zlC",
        "outputId": "03c14da8-9b4d-467b-b078-d9eb5edc7aff"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**[Explanatory Instructions: Towards Unified Vision Tasks Understanding and Zero-shot Generalization](https://arxiv.org/pdf/2412.18525)**<br>Paper not available<br><br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**[On the Compositional Generalization of Multimodal LLMs for Medical Imaging](https://arxiv.org/pdf/2412.20070)**<br>Paper not available<br><br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**[Bringing Objects to Life: 4D generation from 3D objects](https://arxiv.org/pdf/2412.20422)**<br>Paper not available<br><br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**[Efficiently Serving LLM Reasoning Programs with Certaindex](https://arxiv.org/pdf/2412.20993)**<br>Paper not available<br><br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**[TangoFlux: Super Fast and Faithful Text to Audio Generation with Flow Matching and Clap-Ranked Preference Optimization](https://arxiv.org/pdf/2412.21037)**<br>Paper not available<br><br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**[Edicho: Consistent Image Editing in the Wild](https://arxiv.org/pdf/2412.21079)**<br>Paper not available<br><br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**[Facilitating large language model Russian adaptation with Learned Embedding Propagation](https://arxiv.org/pdf/2412.21140)**<br>Paper not available<br><br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**[HumanEval Pro and MBPP Pro: Evaluating Large Language Models on Self-invoking Code Generation](https://arxiv.org/pdf/2412.21199)**<br>Paper not available<br><br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**[Training Software Engineering Agents and Verifiers with SWE-Gym](https://arxiv.org/pdf/2412.21139)**<br>Paper not available<br><br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**[OneKE: A Dockerized Schema-Guided LLM Agent-based Knowledge Extraction System](https://arxiv.org/pdf/2412.20005)**<br>Paper not available<br><br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**[PERSE: Personalized 3D Generative Avatars from A Single Portrait](https://arxiv.org/pdf/2412.21206)**<br>Paper not available<br><br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**[Slow Perception: Let's Perceive Geometric Figures Step-by-step](https://arxiv.org/pdf/2412.20631)**<br>Paper not available<br><br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**[Do NOT Think That Much for 2+3=? On the Overthinking of o1-Like LLMs](https://arxiv.org/pdf/2412.21187)**<br>Paper not available<br><br>"
          },
          "metadata": {}
        }
      ],
      "source": [
        "for paper in papers:\n",
        "    printmd(\"**[{}]({})**<br>{}<br><br>\".format(paper[\"title\"],\n",
        "                                                paper[\"url\"],\n",
        "                                                paper[\"summary\"]))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}